# Handy: Hand Tracking e ClassificaÃ§Ã£o de Gestos em Libras

## ğŸ“Œ VisÃ£o Geral

Este projeto utiliza visÃ£o computacional e machine learning para reconhecer gestos da LÃ­ngua Brasileira de Sinais (Libras) correspondentes ao alfabeto manual. O sistema oferece trÃªs modos de operaÃ§Ã£o: treinamento do modelo, reconhecimento de letras e formaÃ§Ã£o de palavras/frases.

## ğŸ› ï¸ PrÃ©-requisitos

- Python 3.12.6
- OpenCV (`pip install opencv-python`)
- MediaPipe (`pip install mediapipe`)
- scikit-learn (`pip install scikit-learn`)
- joblib (`pip install joblib`)

Ou, simplesmente, instale as dependÃªncias atravÃ©s de `pip install -r requirements.txt`.

## ğŸ“‚ Estrutura de Arquivos

```
â”œâ”€â”€ dados_libras/           # Pasta para armazenar dados de treinamento
    â”œâ”€â”€ a.csv
    â”œâ”€â”€ b.csv
    â””â”€â”€ ...
â”œâ”€â”€ hand_landmarker/        # Pasta com o modelo do MediaPipe
â”‚   â””â”€â”€ hand_landmarker.task
â”œâ”€â”€ main.py                 # Script principal
â”œâ”€â”€ modelo_libras.pkl       # Modelo treinado (gerado apÃ³s treinamento)
â”œâ”€â”€ requirements.txt        # DependÃªncias utilizadas
â”œâ”€â”€ train_model.py          # Script para treinar o modelo


```

## ğŸ® Como Usar

### ğŸ”‘ Teclas de Controle

| Tecla | AÃ§Ã£o |
|-------|------|
| `0` | Ativa modo Treinamento |
| `1` | Ativa modo Normal |
| `2` | Ativa modo Escrita |
| `3` | Ativa modo Escrita (Stop) - pausa captura |
| `EspaÃ§o` | Finaliza palavra atual (modo Escrita) |
| `Enter` | Finaliza frase (modo Escrita) |
| `ESC` | Encerra o programa |

### ğŸ§  Modos de OperaÃ§Ã£o

1. **Modo Normal (Tecla `1`)**
   - Exibe a letra detectada em tempo real
   - NÃ£o armazena as letras para formaÃ§Ã£o de palavras

2. **Modo Treinamento (Tecla `0`)**
   - Permite coletar dados para treinar o modelo
   - Pressione uma tecla (a-z) para salvar a posiÃ§Ã£o da mÃ£o correspondente
   - Os dados sÃ£o armazenados em arquivos CSV na pasta `dados_libras`

3. **Modo Escrita (Tecla `2`)**
   - Captura letras para formar palavras e frases
   - EspaÃ§o: finaliza a palavra atual
   - Enter: finaliza a frase (exibe no terminal)
   - Cooldown de 0.5s entre letras para evitar duplicaÃ§Ãµes

4. **Modo Escrita Stop (Tecla `3`)**
   - Pausa a captura de letras
   - MantÃ©m o progresso atual da frase
   - Ideal para ajustes ou pausas durante a escrita

## ğŸš€ Executando o Projeto

1. Clone o repositÃ³rio
```bash
git clone https://github.com/fcsouzajr/handy.git
```
2. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```
3. Execute o script principal:

```bash
python main.py
```

## ğŸ–¥ï¸ SaÃ­da do Programa

- Janela com visualizaÃ§Ã£o da cÃ¢mera e landmarks da mÃ£o
- Modo atual exibido no topo da tela
- Letra detectada exibida na tela
- No modo Escrita: exibe palavra e frase em formaÃ§Ã£o
- No terminal: feedback das aÃ§Ãµes realizadas

## ğŸ¤– Treinando o Modelo

1. Entre no modo Treinamento (tecla `0`)
2. Para cada letra do alfabeto:
   - Posicione a mÃ£o no gesto correspondente
   - Pressione a tecla da letra (a-z) para capturar
   - Repita vÃ¡rias vezes para criar um conjunto de dados robusto
3. ApÃ³s coletar dados para vÃ¡rias letras, treine o modelo com:
```python
 python train_model.py
```

## ğŸ’¡ Dicas

### Durante o uso
- Mantenha a mÃ£o bem visÃ­vel para a cÃ¢mera
- No modo Escrita, mantenha o gesto por pelo menos 0.5s para ser capturado
- Use o modo Escrita Stop quando precisar fazer pausas
- Para melhor reconhecimento, treine o modelo com vÃ¡rias amostras de cada letra

### Durante o treinamento
- Capture pelo menos 50-100 amostras por letra
- Evite deixar as quantidades de dados de cada letra muito diferentes, para evitar classificaÃ§Ãµes enviesadas
- Mantenha iluminaÃ§Ã£o adequada durante a captura
- Execute `train.model.py`` para gerar a nova versÃ£o do modelo

## ğŸ–ï¸ Sobre o Hand Landmarker
Utilizou-se de base para fazer o handtracking o modelo "Hand Landmarker" disponibilizado pelo MediaPipe do [Google AI for Developers](https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker?hl=pt-br). Ele permite detectar 21 pontos de referÃªncia (landmarks) das mÃ£os em uma imagem, como ilustrado abaixo: 

![Pontos de referÃªncia (landmarks) da mÃ£o detectados pelo MediaPipe](https://ai.google.dev/static/edge/mediapipe/images/solutions/hand-landmarks.png)

*Figura 1: Os 21 landmarks da mÃ£o identificados pelo modelo Hand Landmarker*

AlÃ©m de identificar com precisÃ£o 21 pontos anatÃ´micos da mÃ£o, possui suporte para detecÃ§Ã£o simultÃ¢nea de mÃºltiplas mÃ£os.
